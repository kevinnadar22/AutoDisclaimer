{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking TensorFlow GPU support...\n",
      "TensorFlow version: 2.10.1\n",
      "Physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow is using GPU: 1 GPU(s) available\n",
      "  GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "TensorFlow is built with CUDA support\n",
      "\n",
      "Checking PyTorch GPU support...\n",
      "PyTorch version: 2.6.0+cpu\n",
      "PyTorch is NOT using GPU\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "\n",
    "# Check for TensorFlow GPU support\n",
    "print(\"Checking TensorFlow GPU support...\")\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    \n",
    "    # List physical devices\n",
    "    physical_devices = tf.config.list_physical_devices()\n",
    "    print(\"Physical devices:\", physical_devices)\n",
    "    \n",
    "    # Check specifically for GPU devices\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    if gpu_devices:\n",
    "        print(f\"TensorFlow is using GPU: {len(gpu_devices)} GPU(s) available\")\n",
    "        for i, gpu in enumerate(gpu_devices):\n",
    "            print(f\"  GPU {i}: {gpu}\")\n",
    "    else:\n",
    "        print(\"TensorFlow is NOT using GPU\")\n",
    "        \n",
    "    # Additional TensorFlow GPU info\n",
    "    if tf.test.is_built_with_cuda():\n",
    "        print(\"TensorFlow is built with CUDA support\")\n",
    "    else:\n",
    "        print(\"TensorFlow is NOT built with CUDA support\")\n",
    "except ImportError:\n",
    "    print(\"TensorFlow is not installed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking TensorFlow GPU: {e}\")\n",
    "\n",
    "# Check for PyTorch GPU support\n",
    "print(\"\\nChecking PyTorch GPU support...\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"PyTorch is using GPU\")\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"Number of available GPU devices: {device_count}\")\n",
    "        \n",
    "        # Print information for each GPU\n",
    "        for i in range(device_count):\n",
    "            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"    Memory allocated: {torch.cuda.memory_allocated(i) / 1e9:.2f} GB\")\n",
    "            print(f\"    Memory reserved: {torch.cuda.memory_reserved(i) / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"PyTorch is NOT using GPU\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch is not installed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking PyTorch GPU: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
